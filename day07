一、Pandas分组
1.
Pandas对象可以分成任何对象。有多种方式来拆分对象，如 -
obj.groupby(‘key’)
obj.groupby([‘key1’,’key2’])
obj.groupby(key,axis=1)
ipl_data = {'Team': ['Riders', 'Riders', 'Devils', 'Devils', 'Kings',
'kings', 'Kings', 'Kings', 'Riders', 'Royals', 'Royals', 'Riders'],
'Rank': [1, 2, 2, 3, 3,4 ,1 ,1,2 , 4,1,2],
'Year': [2014,2015,2014,2015,2014,2015,2016,2017,2016,2014,2015,2017],
'Points':[876,789,863,673,741,812,756,788,694,701,804,690]}
df = pd.DataFrame(ipl_data)
print (df.groupby('Team'))
print (df.groupby(['Team','Year']).groups)
2、
使用groupby对象，可以遍历类似itertools.obj的对象。
ipl_data = {'Team': ['Riders', 'Riders', 'Devils', 'Devils', 'Kings',
'kings', 'Kings', 'Kings', 'Riders', 'Royals', 'Royals', 'Riders'],
'Rank': [1, 2, 2, 3, 3,4 ,1 ,1,2 , 4,1,2],
'Year': [2014,2015,2014,2015,2014,2015,2016,2017,2016,2014,2015,2017],
'Points':[876,789,863,673,741,812,756,788,694,701,804,690]}
df = pd.DataFrame(ipl_data)
grouped = df.groupby('Year')
for name,group in grouped:
print (name)
print (group)
3、
使用get_group()方法，可以选择一个组。
ipl_data = {'Team': ['Riders', 'Riders', 'Devils', 'Devils', 'Kings',
'kings', 'Kings', 'Kings', 'Riders', 'Royals', 'Royals', 'Riders'],
'Rank': [1, 2, 2, 3, 3,4 ,1 ,1,2 , 4,1,2],
'Year': [2014,2015,2014,2015,2014,2015,2016,2017,2016,2014,2015,2017],
'Points':[876,789,863,673,741,812,756,788,694,701,804,690]}
df = pd.DataFrame(ipl_data)

grouped = df.groupby('Year')print (grouped.get_group(2014))
4、
聚合函数为每个组返回单个聚合值。当创建了分组(group by)对象，就可以对分组数据执行多个聚合操作。
一个比较常用的是通过聚合或等效的agg方法聚合 -
ipl_data = {'Team': ['Riders', 'Riders', 'Devils', 'Devils', 'Kings',
'kings', 'Kings', 'Kings', 'Riders', 'Royals', 'Royals', 'Riders'],
'Rank': [1, 2, 2, 3, 3,4 ,1 ,1,2 , 4,1,2],
'Year': [2014,2015,2014,2015,2014,2015,2016,2017,2016,2014,2015,2017],
'Points':[876,789,863,673,741,812,756,788,694,701,804,690]}
df = pd.DataFrame(ipl_data)

grouped = df.groupby('Year')print (grouped['Points'].agg(np.mean))
agg = grouped['Points'].agg([np.sum, np.mean, np.std])
5、
过滤根据定义的标准过滤数据并返回数据的子集。filter()函数用于过滤数据。
ipl_data = {'Team': ['Riders', 'Riders', 'Devils', 'Devils', 'Kings',
'kings', 'Kings', 'Kings', 'Riders', 'Royals', 'Royals', 'Riders'],
'Rank': [1, 2, 2, 3, 3,4 ,1 ,1,2 , 4,1,2],
'Year': [2014,2015,2014,2015,2014,2015,2016,2017,2016,2014,2015,2017],
'Points':[876,789,863,673,741,812,756,788,694,701,804,690]}
df = pd.DataFrame(ipl_data)filter = df.groupby('Team').filter(lambda x: len(x) >= 3)
print (filter)

二、Pandas合并
1、
pd.merge(left, right, how='inner', on=None, left_on=None, right_on=None,
left_index=False, right_index=False, sort=True)
left - 一个DataFrame对象。
right - 另一个DataFrame对象。
on - 列(名称)连接，必须在左和右DataFrame对象中存在(找到)。
left_on - 左侧DataFrame中的列用作键，可以是列名或长度等于DataFrame长度的数组。
right_on - 来自右的DataFrame的列作为键，可以是列名或长度等于DataFrame长度的数组。
left_index - 如果为True，则使用左侧DataFrame中的索引(行标签)作为其连接键。 在具有MultiIndex(分层)的DataFrame的情况下，级别的数量必须与来自右DataFrame的连接键的数量相匹配。
right_index - 与右DataFrame的left_index具有相同的用法。
how - 它是left, right, outer以及inner之中的一个，默认为内inner。 下面将介绍每种方法的用法。
sort - 按照字典顺序通过连接键对结果DataFrame进行排序。默认为True，设置为False时，在很多情况下大大提高性能。
left = pd.DataFrame({
'id':[1,2,3,4,5],
'Name': ['Alex', 'Amy', 'Allen', 'Alice', 'Ayoung'],
'subject_id':['sub1','sub2','sub4','sub6','sub5']})
right = pd.DataFrame(
{'id':[1,2,3,4,5],
'Name': ['Billy', 'Brian', 'Bran', 'Bryce', 'Betty'],
'subject_id':['sub2','sub4','sub3','sub6','sub5']})
rs = pd.merge(left,right,on='id')print(rs)
rs = pd.merge(left,right,on=['id','subject_id'])
2、
这里是how选项和SQL等效名称的总结 -
合并方法
SQL等效
描述

left
LEFT OUTER JOIN
使用左侧对象的键

right
RIGHT OUTER JOIN
使用右侧对象的键

outer
FULL OUTER JOIN
使用键的联合

inner
INNER JOIN
使用键的交集

left = pd.DataFrame({
'id':[1,2,3,4,5],
'Name': ['Alex', 'Amy', 'Allen', 'Alice', 'Ayoung'],
'subject_id':['sub1','sub2','sub4','sub6','sub5']})
right = pd.DataFrame(
{'id':[1,2,3,4,5],
'Name': ['Billy', 'Brian', 'Bran', 'Bryce', 'Betty'],
'subject_id':['sub2','sub4','sub3','sub6','sub5']})
rs = pd.merge(left, right, on='subject_id', how='left')print (rs)
rs = pd.merge(left, right, on='subject_id', how='left')
rs = pd.merge(left, right, on='subject_id', how='right')
rs = pd.merge(left, right, how='outer', on='subject_id')
rs = pd.merge(left, right, on='subject_id', how='inner')


三、Pandas级联
1.
concat()函数完成了沿轴执行级联操作的所有重要工作。下面代码中，创建不同的对象并进行连接
one = pd.DataFrame({
'Name': ['Alex', 'Amy', 'Allen', 'Alice', 'Ayoung'],
'subject_id':['sub1','sub2','sub4','sub6','sub5'],
'Marks_scored':[98,90,87,69,78]},
index=[1,2,3,4,5])
two = pd.DataFrame({
'Name': ['Billy', 'Brian', 'Bran', 'Bryce', 'Betty'],
'subject_id':['sub2','sub4','sub3','sub6','sub5'],
'Marks_scored':[89,80,79,97,88]},
index=[1,2,3,4,5])
rs = pd.concat([one,two])print(rs)
rs = pd.concat([one,two],keys=['x','y'])
rs = pd.concat([one,two],keys=['x','y'],ignore_index=True)
2、
连接的一个有用的快捷方式是在Series和DataFrame实例的append方法。这些方法实际上早于concat()方法。 它们沿axis=0连接，即索引 -
one = pd.DataFrame({
'Name': ['Alex', 'Amy', 'Allen', 'Alice', 'Ayoung'],
'subject_id':['sub1','sub2','sub4','sub6','sub5'],
'Marks_scored':[98,90,87,69,78]},
index=[1,2,3,4,5])
two = pd.DataFrame({
'Name': ['Billy', 'Brian', 'Bran', 'Bryce', 'Betty'],
'subject_id':['sub2','sub4','sub3','sub6','sub5'],
'Marks_scored':[89,80,79,97,88]},
index=[1,2,3,4,5])
rs = one.append(two)print(rs)
rs = one.append([two,one,two])
3、
创建一个时间范围
time = pd.date_range("12:00", "23:59", freq="30min").time
print(time)

四、Pandas时间差
1.
通过传递字符串，可以创建一个timedelta对象。
timediff = pd.Timedelta('2 days 2 hours 15 minutes 30 seconds')
print(timediff)
2、
可以在Series/DataFrames上执行运算操作，并通过在datetime64 [ns]系列或在时间戳上减法操作来构造timedelta64 [ns]系列。
s = pd.Series(pd.date_range('2018-1-1', periods=3, freq='D'))
td = pd.Series([ pd.Timedelta(days=i) for i in range(3) ])
df = pd.DataFrame(dict(A = s, B = td))
df['C']=df['A']+df['B']
print(df)

五、Pandas数据分类
1.
通过在pandas对象创建中将dtype指定为“category”。
import pandas as pd
s = pd.Series(["a","b","c","a"], dtype="category")
print (s)
cat = pd.Categorical(['a', 'b', 'c', 'a', 'b', 'c'])
print (cat)
2、
cat=pd.Categorical(['a','b','c','a','b','c','d'], ['c', 'b', 'a'])
cat = cat=pd.Categorical(['a','b','c','a','b','c','d'], ['c', 'b', 'a'])
print (cat)
这里，第二个参数表示类别。因此，在类别中不存在的任何值将被视为NaN
3、
重命名类别是通过将新值分配给series.cat.categories属性来完成的
s = pd.Series(["a","b","c","a"], dtype="category")
s.cat.categories = ["Group %s" % g for g in s.cat.categories]
print (s.cat.categories)
4、
使用Categorical.add.categories()方法，可以追加新的类别。
s = pd.Series(["a","b","c","a"], dtype="category")
s = s.cat.add_categories([4])print (s.cat.categories)
5、
使用Categorical.remove_categories()方法，可以删除不需要的类别。
s = pd.Series(["a","b","c","a"], dtype="category")
print ("Original object:")
print (s)
print("=====================================")
print ("After removal:")
print (s.cat.remove_categories("a"))

六、Pandas数据可视化
1.
如果索引由日期组成，则调用gct().autofmt_xdate()来格式化x轴，如上图所示。
我们可以使用x和y关键字绘制一列与另一列。
绘图方法允许除默认线图之外的少数绘图样式。 这些方法可以作为plot()的kind关键字参数提供。这些包括 -
bar或barh为条形
hist为直方图
boxplot为盒型图
area为“面积”
scatter为散点图
Boxplot可以绘制调用Series.box.plot()和DataFrame.box.plot()或DataFrame.boxplot()来可视化每列中值的分布。
区域块图形以使用Series.plot.area()或DataFrame.plot.area()方法创建区域图形。
饼状图可以使用DataFrame.plot.pie()方法创建。
import pandas as pd
import numpy as np
# 堆积条形图
df = pd.DataFrame(np.random.rand(10,4),columns=['a','b','c','d'])
df.plot.bar()
#水平条形图
df.plot.barh(stacked=True)
# 直方图
df = pd.DataFrame({'a':np.random.randn(1000)+1,'b':np.random.randn(1000),'c':
np.random.randn(1000) - 1}, columns=['a', 'b', 'c'])
df.plot.hist(bins=20)
#为每列绘制不同的直方图
df=pd.DataFrame({'a':np.random.randn(1000)+1,'b':np.random.randn(1000),'c':
np.random.randn(1000) - 1}, columns=['a', 'b', 'c'])
df.hist(bins=20)
#箱型图
df = pd.DataFrame(np.random.rand(10, 5), columns=['A', 'B', 'C', 'D', 'E'])
df.plot.box()
# 区域块图形
df = pd.DataFrame(np.random.rand(10, 4), columns=['a', 'b', 'c', 'd'])
df.plot.area()
#散点图
df = pd.DataFrame(np.random.rand(50, 4), columns=['a', 'b', 'c', 'd'])
df.plot.scatter(x='a', y='b')
# 饼状图
df = pd.DataFrame(3 * np.random.rand(4), index=['a', 'b', 'c', 'd'], columns=['x'])
df.plot.pie(subplots=True)


七、Pandas IO工具
1.
Pandas I/O API是一套像pd.read_csv()一样返回Pandas对象的顶级读取器函数。
读取文本文件(或平面文件)的两个主要功能是read_csv()和read_table()。它们都使用相同的解析代码来智能地将表格数据转换为DataFrame对象 -
import pandas as pd
df=pd.read_csv("temp.csv")
print (df)
df=pd.read_csv("temp.csv",index_col=['S.No'])
print (df)
2、
dtype的列可以作为字典传递。
df = pd.read_csv("temp.csv", dtype={'Salary': np.float64})
print (df.dtypes)
3、
使用names参数指定标题的名称。
df=pd.read_csv("temp.csv", names=['a', 'b', 'c','d','e'])print (df)
4、
skiprows跳过指定的行数。
df=pd.read_csv("temp.csv", skiprows=2)
print (df)

八、Pandas稀疏数据
1.
当任何匹配特定值的数据(NaN/缺失值，尽管可以选择任何值)被省略时，稀疏对象被“压缩”。 一个特殊的SparseIndex对象跟踪数据被“稀疏”的地方。 这将在一个例子中更有意义
ts = pd.Series(np.random.randn(10))
ts[2:-2] = np.nan
sts = ts.to_sparse()
print (sts)
2、
通过调用to_dense可以将任何稀疏对象转换回标准密集形式 -
ts = pd.Series(np.random.randn(10))
ts[2:-2] = np.nan
sts = ts.to_sparse()
print (sts.to_dense())
3、
稀疏数据应该具有与其密集表示相同的dtype。 目前，支持float64，int64和booldtypes。 取决于原始的dtype，fill_value默认值的更改 -
float64 − np.nan
int64 − 0
bool − False


九、 Pandas与SQL的比较
1.
在SQL中，选择是使用逗号分隔的列列表(或选择所有列)来完成的， 在Pandas中，列的选择是通过传递列名到DataFrame
SELECT total_bill, tip, smoker, time
FROM tips
LIMIT 5;

tips=pd.read_csv(url)
rs = tips[['total_bill', 'tip', 'smoker', 'time']].head(5)print(rs)
2、
数据帧可以通过多种方式进行过滤; 最直观的是使用布尔索引
tips=pd.read_csv(url)
rs = tips[tips['time'] == 'Dinner'].head(5)print(rs)
3、
此操作将获取整个数据集中每个组的记录数。 例如，一个查询提取性别的数量(即，按性别分组)  在Pandas中的等值语句将是 -
SELECT sex, count(*)FROM tips
GROUP BY sex;
tips=pd.read_csv(url)
rs = tips.groupby('sex').size()print(rs)
